corpus_path: indexes/general_knowledge.jsonl
data_dir: dataset/
dataset_name: nq
dataset_path: dataset/nq
device: !!python/object/apply:torch.device
- cuda
faiss_gpu: false
framework: fschat
generation_params:
  max_tokens: 32
generator_batch_size: 4
generator_max_input_len: 1024
generator_model: llama2-7B-chat
generator_model_path: /root/autodl-tmp/FlashRAG/Llama-2-7b-chat
gpu_id: 0,1,2,3
gpu_memory_utilization: 0.85
index_path: indexes/e5_Flat.index
method2index:
  bm25: null
  contriever: null
  e5: null
metric_setting:
  retrieval_recall_topk: 5
  tokenizer_name: gpt-4
metrics:
- em
- f1
- sub_em
model2path:
  bge: intfloat/e5-base-v2
  contriever: facebook/contriever
  e5: /root/autodl-tmp/FlashRAG/e5-base-v2
  llama2-13B: meta-llama/Llama-2-13b-hf
  llama2-13B-chat: meta-llama/Llama-2-13b-chat-hf
  llama2-7B: meta-llama/Llama-2-7b-hf
  llama2-7B-chat: /root/autodl-tmp/FlashRAG/Llama-2-7b-chat
model2pooling:
  bge: cls
  contriever: mean
  dpr: cls
  e5: mean
  jina: mean
openai_setting:
  api_key: null
  base_url: null
random_sample: false
rerank_batch_size: 256
rerank_max_length: 512
rerank_model_name: null
rerank_model_path: null
rerank_pooling_method: null
rerank_topk: 5
rerank_use_fp16: true
retrieval_batch_size: 256
retrieval_cache_path: null
retrieval_method: e5
retrieval_model_path: /root/autodl-tmp/FlashRAG/e5-base-v2
retrieval_pooling_method: mean
retrieval_query_max_length: 128
retrieval_topk: 1
retrieval_use_fp16: true
save_dir: output/nq_2024_07_05_21_47_experiment
save_intermediate_data: true
save_metric_score: true
save_note: experiment
save_retrieval_cache: true
seed: 2024
split:
- test
test_sample_num: null
use_fid: false
use_reranker: false
use_retrieval_cache: false
use_sentence_transformer: false
